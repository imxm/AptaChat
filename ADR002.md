# ADR002: Static ETL Using IOC with Transformers Per Data Point

## Status  
Accepted  

## Context  
In the **Static ETL** pipeline, the transformers are predefined and operate specifically on fixed data points (e.g., token volumes, wallet activity). Using the **Inversion of Control (IOC)** principle ensures that each data point has its own dedicated transformer, storage handler, and pipeline logic. This modularity allows for clear separation of concerns, improving maintainability and scalability.

The **static pipeline** will take the following as inputs for each data point:  
1. **Data Point**: Specifies what needs to be fetched and processed (e.g., `token_volume`, `wallet_activity`).  
2. **Transformer**: A static, predefined transformer that processes raw data for that specific data point.  
3. **Storage Handler**: Specifies how and where the transformed data is stored (e.g., in-memory cache, local database).  

The predefined list of static data points is documented here:  
[Static Data Points Documentation](https://docs.google.com/document/d/1_rZ8OyYdVETFfojTnDDSAstpRGWeZb_tZMXwQ99BpRQ/edit?tab=t.0)

## Decision  
The Static ETL pipeline MUST:  
1. Follow the **IOC principle** to inject data points, transformers, and storage handlers dynamically into the pipeline for flexibility.  
2. Define **transformers per data point**, ensuring that each transformation is tailored to the specific requirements of the data point.  
3. Modularize the pipeline to support per-data-point operations, enabling future extensibility without rewriting the entire pipeline.  

The data-fetching queries SHOULD remain flexible and constructed dynamically to accommodate different sources and request formats (e.g., GraphQL, REST).

## Implementation Details  

### **IOC-Based Static ETL Design**  

```python
class StaticTransformer:
    """Static transformers are predefined per data point."""

    def __init__(self):
        # Map data points to their respective transformation logic
        self.transformers = {
            "token_volume": self._transform_token_volume,
            "wallet_activity": self._transform_wallet_activity,
        }

    def transform(self, data_point: str, raw_data: dict) -> dict:
        transformer = self.transformers.get(data_point)
        if not transformer:
            raise ValueError(f"No transformer defined for data point: {data_point}")
        return transformer(raw_data)

    def _transform_token_volume(self, raw_data: dict) -> dict:
        """Example: Aggregate token volume."""
        return {
            "token": raw_data["token"],
            "volume": sum(txn["amount"] for txn in raw_data["transactions"]),
        }

    def _transform_wallet_activity(self, raw_data: dict) -> dict:
        """Example: Count wallet transactions."""
        return {
            "wallet": raw_data["wallet"],
            "activity_count": len(raw_data["transactions"]),
        }


class StaticETL:
    """IOC-based Static ETL pipeline."""

    def __init__(self, fetcher, transformer, storage):
        self.fetcher = fetcher
        self.transformer = transformer
        self.storage = storage

    def execute_pipeline(self, data_points: list):
        """Execute the pipeline for a list of data points."""
        for data_point in data_points:
            raw_data = self.fetcher.fetch(data_point)  # Dynamic queries per data point
            transformed_data = self.transformer.transform(data_point, raw_data)
            self.storage.store(data_point, transformed_data)


# Example usage with mock fetcher and storage
class MockFetcher:
    """Mock data fetcher for demonstration."""
    def fetch(self, data_point):
        # Mock raw data based on data point
        if data_point == "token_volume":
            return {"token": "XYZ", "transactions": [{"amount": 100}, {"amount": 200}]}
        elif data_point == "wallet_activity":
            return {"wallet": "0xABC", "transactions": [{"id": 1}, {"id": 2}]}


class MockStorage:
    """Mock storage handler for demonstration."""
    def store(self, data_point, data):
        print(f"Stored data for {data_point}: {data}")


if __name__ == "__main__":
    # Instantiate components
    fetcher = MockFetcher()
    transformer = StaticTransformer()
    storage = MockStorage()

    # Pass components to StaticETL
    etl_pipeline = StaticETL(fetcher, transformer, storage)

    # Execute pipeline for predefined data points
    etl_pipeline.execute_pipeline(["token_volume", "wallet_activity"])
